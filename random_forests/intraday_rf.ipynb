{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-03-18T20:22:15.220184Z","iopub.status.busy":"2022-03-18T20:22:15.219861Z","iopub.status.idle":"2022-03-18T20:22:15.233305Z","shell.execute_reply":"2022-03-18T20:22:15.232618Z","shell.execute_reply.started":"2022-03-18T20:22:15.220150Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-05-16 23:24:32.647489: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n","2022-05-16 23:24:32.647531: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"]}],"source":["import pickle\n","import re\n","import sys\n","from copy import deepcopy\n","from dataclasses import dataclass\n","from datetime import date, datetime, timedelta\n","from functools import partial\n","from importlib import reload\n","from pathlib import Path\n","\n","import get_data\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import plotly.express as px\n","import plotly.io as pio\n","import pytorch_lightning as pl\n","import pytz\n","import talib\n","import wandb\n","import yfinance as yf\n","from datasets import assets\n","from sklearn import metrics\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.svm import SVC\n","from tools import inspect_code, plotting, training, wandb_api\n","from torch.utils.data import DataLoader, Dataset, TensorDataset\n","from tqdm import tqdm\n","from wandb.keras import WandbCallback\n","\n","import utils\n","\n","log_wandb = False\n","repo_path = Path().resolve().parent\n","pio.renderers.default = \"browser\""]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-03-18T20:20:02.285076Z","iopub.status.busy":"2022-03-18T20:20:02.284804Z","iopub.status.idle":"2022-03-18T20:20:10.841531Z","shell.execute_reply":"2022-03-18T20:20:10.840786Z","shell.execute_reply.started":"2022-03-18T20:20:02.285044Z"},"trusted":true},"outputs":[],"source":["# if log_wandb:\n","#     import wandb\n","\n","#     wandb_api.login()\n","#     run = wandb.init(\n","#         project=\"crypto-prediction\",\n","#         group=\"Initial Gan\",\n","#         job_type=\"test\",\n","#     )\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["interesting_tickers = [\n","    \"XRP\",\n","    \"EOS\",\n","    \"NEO\",\n","    \"ALGO\",\n","    \"SNX\",\n","    \"ETH\",\n","    \"AAVE\",\n","    \"BNB\",\n","    \"BTC\",\n","    \"DOT\",\n","    \"XTZ\",\n","    \"TRX\",\n","    \"ADA\",\n","    \"MATIC\",\n","    \"DOGE\",\n","    \"KLAY\",\n","    \"AVAX\",\n","    \"GRT\",\n","    \"SAND\",\n","    \"SOL\",\n","    \"MANA\",\n","    \"ATOM\",\n","    \"VET\",\n","    \"OMG\",\n","]\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def convert_to_timedelta(interval, ago):\n","    time_equivalence = {\"d\": \"days\", \"h\": \"hours\", \"m\": \"minutes\"}\n","    interval_value, interval_base = re.findall(\"\\d+|\\D+\", interval)\n","    interval_value = ago * int(interval_value)\n","    interval_base = time_equivalence[interval_base]\n","    return timedelta(**{interval_base: interval_value})\n","\n","\n","def compute_metrics(predictions, targets):\n","    if isinstance(predictions, pd.DataFrame) or isinstance(predictions, pd.Series):\n","        predictions = predictions.to_numpy()\n","    if isinstance(targets, pd.DataFrame) or isinstance(targets, pd.Series):\n","        targets = targets.to_numpy()\n","    recall = recall_score(\n","        targets.reshape(-1, 1), predictions.reshape(-1, 1), zero_division=0\n","    )\n","    precision = precision_score(\n","        targets.reshape(-1, 1), predictions.reshape(-1, 1), zero_division=0\n","    )\n","    accuracy = accuracy_score(\n","        targets.reshape(-1, 1),\n","        predictions.reshape(-1, 1),\n","    )\n","    return (\n","        precision,\n","        recall,\n","        accuracy,\n","    )\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train_size: 300, val_size: 0, test_size: 100\n","Length training dataset: 26\n","Length validation dataset: 26\n","Length test dataset: 26\n"]}],"source":["reload(assets)\n","reload(get_data)\n","reload(utils)\n","\n","\n","def _concatenate_indicators(data, lag=5):\n","    data.loc[:, \"useless\"] = 0\n","    data.loc[:, \"open\"] = data.loc[:, \"Open\"].pct_change()\n","    data.loc[:, \"high\"] = data.loc[:, \"High\"].pct_change()\n","    data.loc[:, \"low\"] = data.loc[:, \"Low\"].pct_change()\n","    data.loc[:, \"close\"] = data.loc[:, \"Close\"].pct_change()\n","    data.loc[:, \"volume\"] = data.loc[:, \"Volume\"].pct_change()\n","\n","    # for i in range(5):\n","    #     data.loc[:, f\"open_{i}\"] = data.loc[:, \"Open\"].shift(i).pct_change()\n","    #     data.loc[:, f\"high_{i}\"] = data.loc[:, \"High\"].shift(i).pct_change()\n","    #     data.loc[:, f\"low_{i}\"] = data.loc[:, \"Low\"].shift(i).pct_change()\n","    #     data.loc[:, f\"close_{i}\"] = data.loc[:, \"Close\"].shift(i).pct_change()\n","    #     data.loc[:, f\"volume_{i}\"] = data.loc[:, \"Volume\"].shift(i).pct_change()\n","\n","    # data.loc[:, \"high\"] = data.loc[:, \"High\"].pct_change()\n","    # data.loc[:, \"low\"] = data.loc[:, \"Low\"].pct_change()\n","    # data.loc[:, \"close\"] = data.loc[:, \"Close\"].pct_change()\n","    # data.loc[:, \"volume\"] = data.loc[:, \"Volume\"].pct_change()\n","\n","    # data.loc[:, \"ATR_14\"] = talib.ATR(\n","    #     data.loc[:, \"High\"], data.loc[:, \"Low\"], data.loc[:, \"Open\"], timeperiod=14\n","    # )\n","    # data.loc[:, \"ATR_14\"] = data.loc[:, \"ATR_14\"].pct_change()\n","\n","    # data.loc[:, \"ATR_70\"] = talib.ATR(\n","    #     data.loc[:, \"High\"], data.loc[:, \"Low\"], data.loc[:, \"Open\"], timeperiod=70\n","    # )\n","    # data.loc[:, \"ATR_70\"] = data.loc[:, \"ATR_70\"].pct_change()\n","\n","    # (\n","    #     data.loc[:, \"macd\"],\n","    #     data.loc[:, \"macdsignal\"],\n","    #     data.loc[:, \"macdhist\"],\n","    # ) = talib.MACD(data.loc[:, \"Close\"], fastperiod=12, slowperiod=26, signalperiod=9)\n","    # data.loc[:, \"macd\"] = data.loc[:, \"macd\"].pct_change()\n","    # data.loc[:, \"macdsignal\"] = data.loc[:, \"macdsignal\"].pct_change()\n","    # data.loc[:, \"macdhist\"] = data.loc[:, \"macdhist\"].pct_change()\n","\n","    # (\n","    #     data.loc[:, \"macd2\"],\n","    #     data.loc[:, \"macdsignal2\"],\n","    #     data.loc[:, \"macdhist2\"],\n","    # ) = talib.MACD(data.loc[:, \"Close\"], fastperiod=26, slowperiod=52, signalperiod=9)\n","    # data.loc[:, \"macd2\"] = data.loc[:, \"macd2\"].pct_change()\n","    # data.loc[:, \"macdsignal2\"] = data.loc[:, \"macdsignal2\"].pct_change()\n","    # data.loc[:, \"macdhist2\"] = data.loc[:, \"macdhist2\"].pct_change()\n","\n","    # data.loc[:, \"ADX_14\"] = talib.ADX(\n","    #     data.loc[:, \"High\"], data.loc[:, \"Low\"], data.loc[:, \"Close\"], timeperiod=14\n","    # )\n","    # data.loc[:, \"ADX_14\"] = data.loc[:, \"ADX_14\"].pct_change()\n","\n","    # data.loc[:, \"ADX_70\"] = talib.ADX(\n","    #     data.loc[:, \"High\"], data.loc[:, \"Low\"], data.loc[:, \"Close\"], timeperiod=70\n","    # )\n","    # data.loc[:, \"ADX_70\"] = data.loc[:, \"ADX_70\"].pct_change()\n","\n","    # m = list(range(1, 102, 5))\n","    # for mi in m:\n","    #     data.loc[:, f\"ir_{mi}\"] = data.loc[:, \"Close\"].shift(mi) / data.loc[:, \"Open\"].shift(mi) - 1\n","    # for mi in m:\n","    #     data.loc[:, f\"cr_{mi}\"] = (\n","    #         data.loc[:, \"Close\"].shift(1) / data.loc[:, \"Close\"].shift(mi + 1) - 1\n","    #     )\n","    # for mi in m:\n","    #     data.loc[:, f\"or_{mi}\"] = data.loc[:, \"Open\"] / data.loc[:, \"Close\"].shift(mi) - 1\n","\n","    # scaler = MinMaxScaler()\n","    # l = (\n","    #     [\n","    #         \"open\",\n","    #         \"high\",\n","    #         \"low\",\n","    #         \"close\",\n","    #         \"volume\",\n","    #         \"ATR_14\",\n","    #         \"ATR_70\",\n","    #         \"macd\",\n","    #         \"macdsignal\",\n","    #         \"macdhist\",\n","    #         \"macd2\",\n","    #         \"macdsignal2\",\n","    #         \"macdhist2\",\n","    #         \"ADX_14\",\n","    #         \"ADX_70\",\n","    #     ]\n","    #     + [f\"ir_{mi}\" for mi in m]\n","    #     + [f\"cr_{mi}\" for mi in m]\n","    #     + [f\"or_{mi}\" for mi in m]\n","    # )\n","    # data.loc[\n","    #     :,\n","    #     l,\n","    # ] = scaler.fit_transform(data[l])\n","    data[\"Direction\"] = (data[\"Close\"].shift(-lag) > data[\"Open\"]) & (data[\"Low\"].shift(-1) > data[\"Open\"])\n","    return data\n","\n","\n","class DataModule:\n","    def __init__(\n","        self,\n","        config,\n","        compute_metrics=None,\n","        inputs=None,\n","        save_klines=True,\n","    ):\n","        self.config = config\n","        self.compute_metrics = compute_metrics\n","        self.inputs = inputs\n","        self.save_klines = save_klines\n","\n","    def setup(self):\n","        self.train_datapoints = []\n","        for input in self.inputs:\n","            dp = utils.create_asset(\n","                **input,\n","                interval=self.config[\"interval\"],\n","                compute_metrics=self.compute_metrics,\n","                save_klines=self.save_klines,\n","            )\n","            if dp == []:\n","                continue\n","            dp.df = dp.df.dropna()\n","            dp.labels = dp.labels.dropna()\n","\n","            common_index = dp.df.index.intersection(dp.labels.index)\n","            dp.df = dp.df.loc[common_index]\n","            dp.labels = dp.labels.loc[common_index].astype(\"bool\")\n","\n","            train_dp = assets.TrainAsset(\n","                ticker=input[\"ticker\"],\n","                df=dp.df,\n","                labels=dp.labels,\n","                interval=self.config[\"interval\"],\n","                compute_metrics=self.compute_metrics,\n","            )\n","            if not train_dp.isempty:\n","                self.train_datapoints.append(train_dp)\n","\n","    def clean_datapoints(self, datapoints):\n","        return datapoints\n","\n","    def concat_and_shuffle(self, features, labels):\n","        assert len(features) == len(labels)\n","        _features = np.concatenate(features, axis=0)\n","        _labels = np.concatenate(labels, axis=0)\n","        assert len(_features) == len(_labels)\n","        p = np.random.permutation(len(_features))\n","        return _features[p], _labels[p]\n","\n","    def nest_train_test_val_split(\n","        self, datapoints, offset, train_size, val_size, test_size=0\n","    ):\n","        train_features = []\n","        train_labels = []\n","        val_features = []\n","        val_labels = []\n","        test_datapoints = []\n","        for dp in datapoints:\n","            train_features.append(dp.features[offset : train_size + offset])\n","            train_labels.append(dp.labels[offset : train_size + offset])\n","            val_features.append(\n","                dp.features[train_size + offset : train_size + val_size + offset]\n","            )\n","            val_labels.append(\n","                dp.labels[train_size + offset : train_size + val_size + offset]\n","            )\n","\n","            test_datapoints.append(\n","                assets.TrainAsset(\n","                    ticker=dp.ticker,\n","                    df=dp.df.iloc[\n","                        train_size\n","                        + val_size\n","                        + offset : train_size\n","                        + val_size\n","                        + test_size\n","                        + offset\n","                    ],\n","                    labels=dp.labels.iloc[\n","                        train_size\n","                        + val_size\n","                        + offset : train_size\n","                        + val_size\n","                        + test_size\n","                        + offset\n","                    ],\n","                    interval=dp.interval,\n","                    compute_metrics=dp.compute_metrics,\n","                )\n","            )\n","        return (\n","            self.concat_and_shuffle(train_features, train_labels),\n","            self.concat_and_shuffle(val_features, val_labels),\n","            test_datapoints,\n","        )\n","\n","    def _init_train_val_data(self, train_datapoints):\n","        train_datapoints = self.clean_datapoints(train_datapoints)\n","        if self.config[\"train_val_test_split\"][0] > 1:\n","            train_size = int(self.config[\"train_val_test_split\"][0])\n","        else:\n","            train_size = int(\n","                len(train_datapoints[0].df) * self.config[\"train_val_test_split\"][0]\n","            )\n","        if self.config[\"train_val_test_split\"][1] > 1:\n","            val_size = int(self.config[\"train_val_test_split\"][1])\n","        else:\n","            val_size = int(\n","                len(train_datapoints[0].df) * self.config[\"train_val_test_split\"][1]\n","            )\n","        if self.config[\"train_val_test_split\"][2] > 1:\n","            test_size = int(self.config[\"train_val_test_split\"][2])\n","        else:\n","            test_size = int(\n","                len(train_datapoints[0].df) * self.config[\"train_val_test_split\"][2]\n","            )\n","        print(f\"train_size: {train_size}, val_size: {val_size}, test_size: {test_size}\")\n","        max_offset = len(train_datapoints[0].df) - (train_size + val_size + test_size)\n","        train_datasets = []\n","        val_datasets = []\n","        test_datapoints = []\n","        for offset in range(0, max_offset, val_size + test_size):\n","            train_dataset, val_dataset, test_datapoint = self.nest_train_test_val_split(\n","                train_datapoints, offset, train_size, val_size, test_size\n","            )\n","            train_datasets.append(train_dataset)\n","            val_datasets.append(val_dataset)\n","            test_datapoints.append(test_datapoint)\n","        return train_datasets, val_datasets, test_datapoints\n","\n","\n","config = {}\n","\n","config[\"job_type\"] = run.job_type if \"run\" in locals() else \"test\"\n","config[\"train_val_test_split\"] = [300, 0, 100]\n","config[\"interval\"] = \"1h\"\n","config[\"ago\"] = 3000\n","\n","inputs = [\n","    {\n","        \"ticker\": ticker,\n","        \"beginning_date\": datetime.combine(date.today(), datetime.min.time())\n","        - convert_to_timedelta(config[\"interval\"], ago=config[\"ago\"]),\n","        \"ending_date\": datetime.combine(date.today(), datetime.min.time()),\n","    }\n","    for ticker in interesting_tickers\n","]\n","\n","dm = DataModule(\n","    config, partial(_concatenate_indicators, lag=1), inputs, save_klines=True\n",")\n","dm.setup()\n","train_datasets, val_datasets, test_datapoints = dm._init_train_val_data(\n","    dm.train_datapoints\n",")\n","print(f\"Length training dataset: {len(train_datasets)}\")\n","print(f\"Length validation dataset: {len(train_datasets)}\")\n","print(f\"Length test dataset: {len(train_datasets)}\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train_size: 300, val_size: 0, test_size: 100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 26/26 [00:55<00:00,  2.15s/it]\n"]},{"name":"stdout","output_type":"stream","text":["LAG: 1\n"]},{"ename":"ZeroDivisionError","evalue":"division by zero","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_527/792147052.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mclassifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"LAG: {lag}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"precision: {avg_precision/counter}, recall: {avg_recall/counter}, accuracy: {avg_accuracy/counter},\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"]}],"source":["config[\"train_val_test_split\"] = [300, 0, 100]\n","for lag in [1]:\n","    dm = DataModule(\n","        config, partial(_concatenate_indicators, lag=lag), inputs, save_klines=True\n","    )\n","    dm.setup()\n","    train_datasets, val_datasets, test_datapoints = dm._init_train_val_data(\n","        dm.train_datapoints\n","    )\n","\n","    avg_precision = 0\n","    avg_recall = 0\n","    avg_accuracy = 0\n","    counter = 0\n","    classifiers = []\n","    for idx, train_dataset in enumerate(tqdm(train_datasets)):\n","        try:\n","            val_dataset = val_datasets[idx]\n","            rf = SVC(C=10, class_weight=\"balanced\")\n","            # rf = RandomForestClassifier(n_estimators=2000, max_depth=6)\n","            rf.fit(train_dataset[0], train_dataset[1])\n","\n","            train_precision, train_recall, train_accuracy = compute_metrics(\n","                rf.predict(train_dataset[0]), train_dataset[1]\n","            )\n","            # precision, recall, accuracy = compute_metrics(\n","            #     rf.predict(val_dataset[0]), val_dataset[1]\n","            # )\n","\n","            # avg_recall += recall\n","            # avg_accuracy += accuracy\n","            # avg_precision += precision\n","            # counter += 1\n","\n","            # print(\"TRAINING\")\n","            # print(\"Precision:\", train_precision)\n","            # print(\"Recall:\", train_recall)\n","            # print(\"Accuracy:\", train_accuracy)\n","            # print(\"VALIDATION\")\n","            # print(\"Precision:\", precision)\n","            # print(\"Recall:\", recall)\n","            # print(\"Accuracy:\", accuracy)\n","            # print(\"----------------------------------------\")\n","        except Exception as e:\n","            print(e)\n","        classifiers.append(rf)\n","    print(f\"LAG: {lag}\")\n","    print(f\"precision: {avg_precision/counter}, recall: {avg_recall/counter}, accuracy: {avg_accuracy/counter},\")"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["XRP: 0.64366373902133 \t 0.8221153846153846 \t 0.8480769230769231\n","EOS: 0.632748538011696 \t 0.8400621118012422 \t 0.8396153846153847\n","NEO: 0.6323851203501094 \t 0.8717948717948718 \t 0.838076923076923\n","ALGO: 0.6027542372881356 \t 0.8647416413373861 \t 0.8215384615384616\n","SNX: 0.5929549902152642 \t 0.9195751138088012 \t 0.8196153846153846\n","ETH: 0.6717752234993615 \t 0.8042813455657493 \t 0.8519230769230769\n","AAVE: 0.5904761904761905 \t 0.9029126213592233 \t 0.828076923076923\n","BNB: 0.6856368563685636 \t 0.7881619937694704 \t 0.8584615384615385\n","BTC: 0.6832844574780058 \t 0.7327044025157232 \t 0.8515384615384616\n","DOT: 0.6028921023359288 \t 0.9124579124579124 \t 0.8426923076923077\n","XTZ: 0.6090621707060063 \t 0.8810975609756098 \t 0.8273076923076923\n","TRX: 0.6896551724137931 \t 0.782608695652174 \t 0.8488461538461538\n","ADA: 0.6223529411764706 \t 0.9120689655172414 \t 0.8569230769230769\n","MATIC: 0.6056955093099672 \t 0.8694968553459119 \t 0.8296153846153846\n","DOGE: 0.5865384615384616 \t 0.8698752228163993 \t 0.8396153846153847\n","KLAY: 0.5596446700507615 \t 0.8091743119266055 \t 0.8265384615384616\n","AVAX: 0.5989637305699482 \t 0.896124031007752 \t 0.8253846153846154\n","GRT: 0.5963488843813387 \t 0.9046153846153846 \t 0.823076923076923\n","SAND: 0.5684782608695652 \t 0.8940170940170941 \t 0.8234615384615385\n","SOL: 0.6220302375809935 \t 0.9201277955271565 \t 0.8461538461538461\n","MANA: 0.606359649122807 \t 0.9035947712418301 \t 0.8392307692307692\n","ATOM: 0.5493697478991597 \t 0.9001721170395869 \t 0.8126923076923077\n","VET: 0.6335078534031413 \t 0.9138972809667674 \t 0.8434615384615385\n","OMG: 0.6243441762854145 \t 0.8920539730134932 \t 0.8346153846153846\n","AVERAGE\n","0.6171217883480172 0.8669888107786988 0.8365224358974362\n"]}],"source":["for index, (classifier, test_datapoint) in enumerate(zip(classifiers, test_datapoints)):\n","    if index == 0:\n","        base_datapoints = {dp.ticker: deepcopy(dp) for dp in test_datapoint}\n","        for ticker in base_datapoints.keys():\n","            base_datapoints[ticker].predictions = classifier.predict(\n","                base_datapoints[ticker].features\n","            )\n","            # base_datapoints[ticker].probabilities = classifier.predict_proba(base_datapoints[ticker].features)[:, 1]\n","    else:\n","        for dp in test_datapoint:\n","            base_datapoints[dp.ticker].df = pd.concat(\n","                [base_datapoints[dp.ticker].df, dp.df]\n","            )\n","            base_datapoints[dp.ticker].labels = pd.concat(\n","                [base_datapoints[dp.ticker].labels, dp.labels]\n","            )\n","            base_datapoints[dp.ticker].predictions = np.concatenate(\n","                [\n","                    base_datapoints[dp.ticker].predictions,\n","                    classifier.predict(dp.features),\n","                ]\n","            )\n","            # base_datapoints[dp.ticker].probabilities = np.concatenate(\n","            #     [\n","            #         base_datapoints[dp.ticker].probabilities,\n","            #         classifier.predict_proba(dp.features)[:, 1],\n","            #     ]\n","            # )\n","\n","base_precision = 0\n","base_recall = 0\n","base_accuracy = 0\n","for ticker, dp in base_datapoints.items():\n","    predictions = dp.predictions\n","    (\n","        base_datapoints[ticker].precision,\n","        base_datapoints[ticker].recall,\n","        base_datapoints[ticker].accuracy,\n","    ) = compute_metrics(predictions, dp.labels)\n","\n","    base_precision += base_datapoints[ticker].precision\n","    base_recall += base_datapoints[ticker].recall\n","    base_accuracy += base_datapoints[ticker].accuracy\n","\n","    print(\n","        f\"{ticker}: {base_datapoints[ticker].precision} \\t {base_datapoints[ticker].recall} \\t {base_datapoints[ticker].accuracy}\"\n","    )\n","print(\"AVERAGE\")\n","print(base_precision/len(base_datapoints.values()), base_recall/len(base_datapoints.values()), base_accuracy/len(base_datapoints.values()))\n"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/matias/.pyenv/versions/3.9.8/envs/binance/lib/python3.9/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning:\n","\n","\n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","\n"]}],"source":["import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","\n","m = 1\n","\n","fig = make_subplots(\n","    rows=m,\n","    cols=1,\n","    subplot_titles=[dp.ticker for dp in base_datapoints.values()],\n","    horizontal_spacing=0.0001,\n","    vertical_spacing=0.1,\n","    shared_xaxes=True,\n",")\n","\n","for index, (ticker, dp) in enumerate(base_datapoints.items()):\n","    if index >= m:\n","        break\n","    predictions = dp.predictions\n","    labels = dp.labels\n","    df = dp.df\n","\n","    fig.add_trace(\n","        go.Candlestick(\n","            x=df.index,\n","            open=df[\"Open\"],\n","            high=df[\"High\"],\n","            low=df[\"Low\"],\n","            close=df[\"Close\"],\n","        ),\n","        # go.Scatter(\n","        #     x=df.index,\n","        #     y=df[\"Open\"],\n","        #     showlegend=False,\n","        #     line=dict(color=\"black\", width=1),\n","        # ),\n","        row=index + 1,\n","        col=1,\n","    )\n","\n","    lag = 2\n","    open = dp.df.loc[:, \"Open\"].iloc[predictions].to_frame(name=\"price\")\n","    close = (\n","        dp.df.loc[:, \"Close\"]\n","        .shift(1)\n","        .iloc[[False] * lag + list(predictions[:-lag])]\n","        .to_frame(name=\"price\")\n","    )\n","\n","    if True in predictions[-lag:]:\n","        open = open.iloc[:-1]\n","\n","    positive_mask = close[\"price\"].to_numpy() > open[\"price\"].to_numpy()\n","    positive_open = open.iloc[positive_mask]\n","    positive_open.loc[:, \"index\"] = list(range(0, len(positive_open)))\n","    positive_close = close.iloc[positive_mask]\n","    positive_close.loc[:, \"index\"] = np.array(list(range(0, len(positive_close)))) + 0.3\n","    positive_nan_df = pd.DataFrame(\n","        {\"price\": np.nan, \"index\": np.array(list(range(0, len(positive_open)))) + 0.5},\n","        index=positive_open.index,\n","    )\n","    positive_price_df = pd.concat(\n","        [positive_open, positive_close, positive_nan_df]\n","    ).sort_values(\"index\")\n","\n","    negative_mask = close[\"price\"].to_numpy() < open[\"price\"].to_numpy()\n","    negative_open = open.iloc[negative_mask]\n","    negative_open.loc[:, \"index\"] = list(range(0, len(negative_open)))\n","    negative_close = close.iloc[negative_mask]\n","    negative_close.loc[:, \"index\"] = np.array(list(range(0, len(negative_close)))) + 0.3\n","    negative_nan_df = pd.DataFrame(\n","        {\"price\": np.nan, \"index\": np.array(list(range(0, len(negative_open)))) + 0.5},\n","        index=negative_open.index,\n","    )\n","    negative_price_df = pd.concat(\n","        [negative_open, negative_close, negative_nan_df]\n","    ).sort_values(\"index\")\n","\n","    fig.add_trace(\n","        go.Scatter(\n","            x=positive_price_df.index,\n","            y=positive_price_df[\"price\"],\n","            mode=\"lines\",\n","            showlegend=False,\n","            line=dict(color=\"green\"),\n","        ),\n","        row=index + 1,\n","        col=1,\n","    )\n","\n","    fig.add_trace(\n","        go.Scatter(\n","            x=negative_price_df.index,\n","            y=negative_price_df[\"price\"],\n","            mode=\"lines\",\n","            showlegend=False,\n","            line=dict(color=\"red\"),\n","        ),\n","        row=index + 1,\n","        col=1,\n","    )\n","    \n","def zoom(layout, xrange):\n","    in_view = df.loc[fig.layout.xaxis.range[0]:fig.layout.xaxis.range[1]]\n","    fig.layout.yaxis.range = [in_view.High.min() - 10, in_view.High.max() + 10]\n","\n","fig.layout.on_change(zoom, 'xaxis.range')\n","fig.update_layout(height=450*m, width=1000, margin=dict(l=10, r=20, t=30, b=10))\n","fig.show()\n"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["from datetime import datetime, timedelta\n","import vectorbt as vbt\n","\n","vbt.settings.portfolio[\"fees\"] = 0.001\n","vbt.settings.portfolio[\"slippage\"] = 0.0025\n","data = vbt.Data.from_data(\n","    {dp.ticker: dp.df for dp in base_datapoints.values()},\n","    download_kwargs={},\n",")\n","\n","# probabilities = vbt.Data.from_data(\n","#     {dp.ticker: dp.probabilities for dp in base_datapoints.values()},\n","#     download_kwargs={},\n","# )\n","# predictions = pd.DataFrame(\n","#     probabilities.get().values.argsort(axis=1) > 20,\n","#     columns=probabilities.get().columns,\n","#     index=data.get(\"Open\").index,\n","# )\n","predictions = vbt.Data.from_data(\n","    {dp.ticker: (dp.predictions) & (dp.df[\"Low\"].shift(-1) > dp.df[\"Open\"]) for dp in base_datapoints.values()},\n","    download_kwargs={},\n",").get().set_index(data.get(\"Open\").index)\n","\n"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"data":{"text/plain":["ohlcstcx_sl_stop  ohlcstcx_sl_trail  ohlcstcx_tp_stop  symbol\n","1                 True               1                 SNX       884.713758\n","                                                       AAVE      217.688148\n","                                                       GRT       208.297247\n","                                                       AVAX      206.120314\n","                                                       VET       114.720291\n","                                                       MANA       98.681459\n","                                                       SAND       98.457012\n","                                                       SOL        97.924417\n","                                                       OMG        96.581529\n","                                                       ATOM       62.458016\n","                                                       XTZ        56.012370\n","                                                       NEO        49.037215\n","                                                       MATIC      47.036981\n","                                                       ALGO       42.591039\n","                                                       DOT        36.074623\n","                                                       ADA        21.706818\n","                                                       EOS        16.367916\n","                                                       DOGE       13.635125\n","                                                       XRP        10.248994\n","                                                       TRX         9.685941\n","                                                       ETH         8.388101\n","                                                       BNB         3.787693\n","                                                       KLAY        3.075252\n","                                                       BTC         2.580764\n","Name: total_return, dtype: float64"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# def apply_rf(*args, **kwargs):\n","#     proba = kwargs[\"proba\"]\n","#     price = np.squeeze(np.stack(args[1:], axis=1))\n","#     length = price.shape[0]\n","#     try:\n","#         probabilities = rf.predict_proba(price)\n","#         direction = np.argmax(probabilities > proba, axis=1)\n","#     except ValueError:\n","#         direction = np.zeros(length)\n","#     return direction\n","\n","\n","# def plot_trix(trix, signal, column=None, fig=None):\n","#     fig = trix.vbt.plot(fig=fig)\n","#     fig = signal.vbt.plot(fig=fig)\n","\n","\n","# RF = vbt.IndicatorFactory(\n","#     input_names=list(data.data.values())[0].columns[6:],\n","#     output_names=[\"direction\"],\n","#     # subplots=dict(\n","#     #     plot_outputs=dict(\n","#     #         plot_func=plot_trix,\n","#     #         resolve_trix=True,\n","#     #         resolve_signal=True,\n","#     #     )\n","#     # ),\n","# ).from_apply_func(\n","#     apply_rf,\n","#     proba=0.5,\n","# )\n","# direction = RF.run(\n","#     *data.get()[6:],\n","#     run_unique=True,\n","#     short_name=\"entries\",\n","#     per_column=True,\n","#     pass_col=True\n","# )\n","# trend_ma = vbt.MA.run(data.get(\"Close\"), window=50, ewm=True, run_unique=True)\n","\n","ohlcstcx = vbt.OHLCSTCX.run(\n","    entries=predictions,\n","    open=data.get(\"Open\"),\n","    high=data.get(\"High\"),\n","    low=data.get(\"Low\"),\n","    close=data.get(\"Close\"),\n","    sl_stop=1,\n","    sl_trail=True,\n","    tp_stop=1,\n",")\n","\n","exits = ~predictions | ohlcstcx.exits\n","entries =  ohlcstcx.entries\n","\n","\n","pf = vbt.Portfolio.from_signals(\n","    data.get(\"Open\"),\n","    entries=entries,\n","    exits=exits,\n","    freq=timedelta(hours=1),\n",")\n","total_return = pf.total_return()\n","total_return.sort_values(ascending=False)\n","# total_return, total_return[total_return != 0].mean(), total_return[\n","#     total_return != 0\n","# ].median()"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"data":{"text/plain":["Start                         2022-01-23 13:00:00+00:00\n","End                           2022-05-11 20:00:00+00:00\n","Period                                108 days 08:00:00\n","Start Value                                       100.0\n","End Value                                    358.076433\n","Total Return [%]                             258.076433\n","Benchmark Return [%]                         -17.962077\n","Max Gross Exposure [%]                            100.0\n","Total Fees Paid                              167.214081\n","Max Drawdown [%]                               4.077526\n","Max Drawdown Duration                  12 days 09:00:00\n","Total Trades                                        365\n","Total Closed Trades                                 365\n","Total Open Trades                                     0\n","Open Trade PnL                                      0.0\n","Win Rate [%]                                  49.863014\n","Best Trade [%]                                 7.533664\n","Worst Trade [%]                               -0.566194\n","Avg Winning Trade [%]                          0.974862\n","Avg Losing Trade [%]                           -0.25898\n","Avg Winning Trade Duration    0 days 01:32:38.241758241\n","Avg Losing Trade Duration     0 days 01:00:39.344262295\n","Profit Factor                                  3.176384\n","Expectancy                                     0.707059\n","Sharpe Ratio                                  11.769552\n","Calmar Ratio                                 1778.80595\n","Omega Ratio                                    1.982929\n","Sortino Ratio                                 35.462871\n","Name: (1, True, 1, BTC), dtype: object"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["pf.loc[total_return.sort_values(ascending=False).index[-1]].stats()"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"text/plain":["Start                         2022-01-23 13:00:00+00:00\n","End                           2022-05-11 20:00:00+00:00\n","Period                                108 days 08:00:00\n","Start Value                                       100.0\n","End Value                                  21868.814841\n","Total Return [%]                           21768.814841\n","Benchmark Return [%]                         -47.073791\n","Max Gross Exposure [%]                            100.0\n","Total Fees Paid                             2833.322626\n","Max Drawdown [%]                               0.811995\n","Max Drawdown Duration                   1 days 08:00:00\n","Total Trades                                        394\n","Total Closed Trades                                 394\n","Total Open Trades                                     0\n","Open Trade PnL                                      0.0\n","Win Rate [%]                                  85.532995\n","Best Trade [%]                                12.103071\n","Worst Trade [%]                               -0.465054\n","Avg Winning Trade [%]                          1.661859\n","Avg Losing Trade [%]                          -0.187091\n","Avg Winning Trade Duration    0 days 01:29:11.928783382\n","Avg Losing Trade Duration               0 days 01:00:00\n","Profit Factor                                 72.411372\n","Expectancy                                    55.250799\n","Sharpe Ratio                                   25.29795\n","Calmar Ratio                          9415811566.419516\n","Omega Ratio                                    4.969761\n","Sortino Ratio                                144.887588\n","Name: (1, True, 1, AAVE), dtype: object"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["pf.loc[total_return.sort_values(ascending=False).index[1]].stats()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"321abdbcb709f963ff456ab1955c8b6ac962fdf45411881beed91e0e00a7d370"},"kernelspec":{"display_name":"Python 3.9.8 64-bit ('binance')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.8"}},"nbformat":4,"nbformat_minor":4}
