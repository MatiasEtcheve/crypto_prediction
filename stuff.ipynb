{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Computation device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import date, datetime, timedelta\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from typing import Annotated\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import pytz\n",
    "import talib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "import vectorbt as vbt\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchviz import make_dot\n",
    "\n",
    "import get_data\n",
    "from tools import dataframe_reformat, inspect_code, plotting, training, wandb_api\n",
    "\n",
    "log_wandb = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {\"num_workers\": 2, \"pin_memory\": True} if use_cuda else {\"num_workers\": 4}\n",
    "print(f\"[INFO]: Computation device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:39a4uiwc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aea250cdbdf4110856fc0fd7c5923db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>close_generator</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>d_loss</td><td>█████████████████████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▂▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>fake_discriminator</td><td>█████████████████▇▇▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▃▃▁</td></tr><tr><td>fake_generator</td><td>█████████████████▇▇▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▁</td></tr><tr><td>g_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆█</td></tr><tr><td>real_discriminator</td><td>█████████████████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▆▄▄▄▄▃▃▁</td></tr><tr><td>sign_generator</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_close_generator</td><td>█▃▁▂▁▁▁▁▁▁▁▁▂▂▃▃▁▁▂▁▅▅▁▂▂▂▂▂▄▂▂▂▂▂▃▂▂▂▂▂</td></tr><tr><td>val_d_loss</td><td>████████████████████▇▇▇▇█▇█▇▇█▇▆▇▇▇▇▇▄█▁</td></tr><tr><td>val_fake_discriminator</td><td>████████████████████▇▇▇▇▇▇▆▆▆▅▇▆▆▄▅▅▄▄▁▃</td></tr><tr><td>val_fake_generator</td><td>████████████████████▇▇▇▇▇▇▆▆▆▅▇▆▆▄▅▅▄▄▁▃</td></tr><tr><td>val_g_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▄▂▃▃▅▄▄▅▅█▆</td></tr><tr><td>val_real_discriminator</td><td>█████████████████████▇▇█▇▇▆▆▆▅▇▆▆▄▅▅▅▆▁▅</td></tr><tr><td>val_sign_generator</td><td>▇▄▂▃▁▁▁▁▁▁▂▂▂▃▄▃▂▃▃▂█▇▃▂▆▄▃▄▇▃▃▃▄▄▅▄▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>close_generator</td><td>0.01797</td></tr><tr><td>d_loss</td><td>-79520368.0</td></tr><tr><td>epoch</td><td>61</td></tr><tr><td>fake_discriminator</td><td>-422543616.0</td></tr><tr><td>fake_generator</td><td>-430317664.0</td></tr><tr><td>g_loss</td><td>430317664.0</td></tr><tr><td>real_discriminator</td><td>-343023392.0</td></tr><tr><td>sign_generator</td><td>0.11508</td></tr><tr><td>trainer/global_step</td><td>31123</td></tr><tr><td>val_close_generator</td><td>0.01582</td></tr><tr><td>val_d_loss</td><td>-224243760.0</td></tr><tr><td>val_fake_discriminator</td><td>-460370688.0</td></tr><tr><td>val_fake_generator</td><td>-460370688.0</td></tr><tr><td>val_g_loss</td><td>460370688.0</td></tr><tr><td>val_real_discriminator</td><td>-236127056.0</td></tr><tr><td>val_sign_generator</td><td>0.09882</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">toasty-elevator-9</strong>: <a href=\"https://wandb.ai/matiasetcheverry/binance/runs/39a4uiwc\" target=\"_blank\">https://wandb.ai/matiasetcheverry/binance/runs/39a4uiwc</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 4 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220311_131801-39a4uiwc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:39a4uiwc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matias/binance/wandb/run-20220311_141809-omrb0pxg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/matiasetcheverry/binance/runs/omrb0pxg\" target=\"_blank\">leafy-breeze-10</a></strong> to <a href=\"https://wandb.ai/matiasetcheverry/binance\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if log_wandb:\n",
    "    import wandb\n",
    "\n",
    "    wandb_api.login()\n",
    "    run = wandb.init(\n",
    "        project=\"binance\",\n",
    "        group=\"Initial GAN\",\n",
    "        job_type=\"test\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if log_wandb:\n",
    "    config = wandb.config\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "\n",
    "config[\"job_type\"] = run.job_type if \"run\" in locals() else \"test\"\n",
    "config[\"log_wandb\"] = log_wandb\n",
    "config[\"train_test_split\"] = 0.7\n",
    "config[\"nb_previous_close\"] = 20\n",
    "config[\"batch_size\"] = 16\n",
    "config[\"learning_rate_generator\"] = 0.0001\n",
    "config[\"learning_rate_discriminator\"] = 0.0004\n",
    "config[\"beta1\"] = 0.5\n",
    "config[\"beta2\"] = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        csv_file=None,\n",
    "        train_df=None,\n",
    "        test_df=None,\n",
    "        train_dataset=None,\n",
    "        validation_dataset=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        if csv_file is not None:\n",
    "            self.df = pd.read_csv(csv_file, delimiter=\";\")\n",
    "            self.df[\"BEGINNING_DATE\"] = pd.to_datetime(\n",
    "                self.df[\"BEGINNING_DATE\"], dayfirst=True\n",
    "            )\n",
    "            self.df[\"ENDING_DATE\"] = pd.to_datetime(\n",
    "                self.df[\"ENDING_DATE\"], dayfirst=True\n",
    "            )\n",
    "            self.df[\"TICKER\"] += \"-USD\"\n",
    "\n",
    "        self.train_df = train_df.convert_dtypes() if train_df is not None else None\n",
    "        self.test_df = test_df.convert_dtypes() if test_df is not None else None\n",
    "        self.train_dataset = train_dataset\n",
    "        self.validation_dataset = validation_dataset\n",
    "\n",
    "    def preprocess_klines(\n",
    "        self,\n",
    "        data=None,\n",
    "        ticker=None,\n",
    "        beginning_date=None,\n",
    "        ending_date=None,\n",
    "        interval=\"1d\",\n",
    "    ):\n",
    "        if data is None:\n",
    "            data = get_data.select_data(\n",
    "                ticker,\n",
    "                interval,\n",
    "                beginning_date=beginning_date,\n",
    "                ending_date=ending_date,\n",
    "            )\n",
    "        data.dropna(axis=0, inplace=True)\n",
    "        data.drop(labels=\"Date\", axis=1, inplace=True)\n",
    "        data.replace(\n",
    "            to_replace=[np.inf, -np.inf, np.float64(\"inf\"), -np.float64(\"inf\")],\n",
    "            value=0,\n",
    "            inplace=True,\n",
    "        )\n",
    "        idx_close = list(data.columns).index(\"Close\")\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        klines = torch.FloatTensor(scaler.fit_transform(data))\n",
    "\n",
    "        data_close = klines[:, idx_close]\n",
    "        single_close = torch.FloatTensor(data_close[self.config[\"nb_previous_close\"] :])\n",
    "        multiple_close = torch.stack(\n",
    "            [\n",
    "                torch.FloatTensor(data_close[i : i + self.config[\"nb_previous_close\"]])\n",
    "                for i in range(len(data_close) - self.config[\"nb_previous_close\"])\n",
    "            ]\n",
    "        )\n",
    "        multiple_klines = torch.stack(\n",
    "            [\n",
    "                klines[i : i + self.config[\"nb_previous_close\"], :]\n",
    "                for i in range(len(klines) - self.config[\"nb_previous_close\"])\n",
    "            ]\n",
    "        )\n",
    "        return multiple_klines, single_close, multiple_close\n",
    "\n",
    "    def prepare_data(self):\n",
    "        for _, row in self.df.iterrows():\n",
    "            _ = get_data.select_data(\n",
    "                row[\"TICKER\"],\n",
    "                \"1d\",\n",
    "                beginning_date=row[\"BEGINNING_DATE\"],\n",
    "                ending_date=row[\"ENDING_DATE\"],\n",
    "            )\n",
    "\n",
    "    def setup(self, stage):\n",
    "        klines_training_sets = []\n",
    "        single_close_training_sets = []\n",
    "        multiple_close_training_sets = []\n",
    "        klines_validation_sets = []\n",
    "        single_close_validation_sets = []\n",
    "        multiple_close_validation_sets = []\n",
    "        for _, row in self.df.iterrows():\n",
    "            klines, single_close, multiple_close = self.preprocess_klines(\n",
    "                ticker=row[\"TICKER\"],\n",
    "                beginning_date=row[\"BEGINNING_DATE\"],\n",
    "                ending_date=row[\"ENDING_DATE\"],\n",
    "            )\n",
    "            n = len(klines)\n",
    "            klines_training_sets.append(\n",
    "                klines[: int(n * self.config[\"train_test_split\"]), :, :]\n",
    "            )\n",
    "            single_close_training_sets.append(\n",
    "                single_close[: int(n * self.config[\"train_test_split\"])]\n",
    "            )\n",
    "            multiple_close_training_sets.append(\n",
    "                multiple_close[: int(n * self.config[\"train_test_split\"])]\n",
    "            )\n",
    "\n",
    "            klines_validation_sets.append(\n",
    "                klines[int(n * self.config[\"train_test_split\"]) :, :, :]\n",
    "            )\n",
    "            single_close_validation_sets.append(\n",
    "                single_close[int(n * self.config[\"train_test_split\"]) :]\n",
    "            )\n",
    "            multiple_close_validation_sets.append(\n",
    "                multiple_close[int(n * self.config[\"train_test_split\"]) :]\n",
    "            )\n",
    "        assert len(klines_training_sets) == len(single_close_validation_sets)\n",
    "        assert len(klines_training_sets) == len(multiple_close_training_sets)\n",
    "        self.klines_training_sets = torch.cat(klines_training_sets)\n",
    "        self.single_close_training_sets = torch.cat(\n",
    "            single_close_training_sets\n",
    "        ).unsqueeze(-1)\n",
    "        self.multiple_close_training_sets = torch.cat(multiple_close_training_sets)\n",
    "\n",
    "        self.klines_validation_sets = torch.cat(klines_validation_sets)\n",
    "        self.single_close_validation_sets = torch.cat(\n",
    "            single_close_validation_sets\n",
    "        ).unsqueeze(-1)\n",
    "        self.multiple_close_validation_sets = torch.cat(multiple_close_validation_sets)\n",
    "\n",
    "        self.train_dataset = TensorDataset(\n",
    "            self.klines_training_sets,\n",
    "            self.multiple_close_training_sets,\n",
    "            self.single_close_training_sets,\n",
    "        )\n",
    "        self.validation_dataset = TensorDataset(\n",
    "            self.klines_validation_sets,\n",
    "            self.multiple_close_validation_sets,\n",
    "            self.single_close_validation_sets,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.config[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.validation_dataset,\n",
    "            batch_size=self.config[\"batch_size\"],\n",
    "            shuffle=False,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.val_dataloader()\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(\n",
    "            [image for image, _ in self.validation_dataset],\n",
    "            batch_size=self.config[\"batch_size\"],\n",
    "            shuffle=False,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "dm = DataModule(config, \"DATE.csv\")\n",
    "dm.prepare_data()\n",
    "dm.setup(stage=\"fit\")\n",
    "train_dataloader = dm.train_dataloader()\n",
    "val_dataloader = dm.val_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8032\n",
      "3472\n",
      "torch.Size([16, 20, 29]) torch.Size([16, 20]) torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader) * config[\"batch_size\"])\n",
    "print(len(val_dataloader) * config[\"batch_size\"])\n",
    "klines, single_close, multiple_close = next(iter(train_dataloader))\n",
    "print(klines.shape, single_close.shape, multiple_close.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/.pyenv/versions/3.9.8/envs/binance/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/matias/.pyenv/versions/3.9.8/envs/binance/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:341: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/matias/.pyenv/versions/3.9.8/envs/binance/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | generator     | Generator     | 59.8 K\n",
      "1 | discriminator | Discriminator | 84.3 K\n",
      "------------------------------------------------\n",
      "144 K     Trainable params\n",
      "0         Non-trainable params\n",
      "144 K     Total params\n",
      "0.576     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: not saving models.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7955885bea4384868fff320f228586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03529f6781614ca5a06adceee647316c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa531953aec14d12befaa75f8ea8a989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb4070d89f5454fa45badc519a9df21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1eb8fa7991f462f8c0488ab3693c08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78e5ca3b8e34d84ac0eb426146dbba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b11c820245a4cd8b3fcd0debbffe1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965f769acf8f4c73a7d5c3b923904bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8909ea01c6e1461f930cea9f59b98611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1fac6e739345f19faa53d92b47d748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73162562bff04a96af02816257fa1266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de20924b4e9c42fa970b87e01e663e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e60aea6edff43efad2f51c5b58ab3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cce180f176b465eb0221d76e44c30be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecca19af468483c99760a5ab08d8f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d456a3bd66f49c6acf32e1153486f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f592daa4004cc6aa9cddb7311fe524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bcf873eff74c6e8be4ce5ebb58e4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e157a4d68041b58a88b1b1683cabff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca20abda8dda4b829274fb802d5cc9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f04c09247714066a6d35a6d805b28c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f9fbe887e0498b961bc94fe05a5caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6501552eec0473aac23438b0fe1c66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv1d(config[\"nb_previous_close\"], 32, kernel_size=2),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            28, 64, num_layers=1, batch_first=True, bidirectional=True, dropout=0.3\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            # nn.Flatten(),\n",
    "            nn.Linear(in_features=2 * 64, out_features=64),\n",
    "            nn.LeakyReLU(),\n",
    "            # nn.Dropout2d(0.2),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.LeakyReLU(),\n",
    "            # nn.Dropout2d(0.2),\n",
    "            nn.Linear(in_features=32, out_features=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        output, (hidden_state, cell_state) = self.lstm_layer(x)\n",
    "        hidden_state = torch.permute(hidden_state, (1, 0, 2)).reshape(-1, 2 * 64)\n",
    "        x = self.fc_layers(hidden_state)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(32, 64, kernel_size=2),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        _, nb_filters, width = self.conv_layer(torch.rand(1, 1, 21)).shape\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=nb_filters * width, out_features=64),\n",
    "            nn.LeakyReLU(),\n",
    "            # nn.Dropout2d(0.2),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.LeakyReLU(),\n",
    "            # nn.Dropout2d(0.2),\n",
    "            nn.Linear(in_features=32, out_features=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.conv_layer(z.unsqueeze(1))\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GAN(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # networks\n",
    "        self.generator = Generator(self.config)\n",
    "        self.discriminator = Discriminator(self.config)\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return nn.BCELoss()(y_hat, y)\n",
    "\n",
    "    def generator_loss(self, fake, y_hat, y):\n",
    "        fake_generator = torch.mean(fake)\n",
    "        close_generator = torchmetrics.MeanSquaredError()(y_hat, y)\n",
    "        sign_generator = torch.mean(torch.abs(torch.sign(y_hat) - torch.sign(y)))\n",
    "        return fake_generator, close_generator, sign_generator\n",
    "\n",
    "    def discriminator_loss(self, real, fake, y_hat, y):\n",
    "        fake_discriminator = torch.mean(fake)\n",
    "        real_discriminator = torch.mean(real)\n",
    "        return fake_discriminator, real_discriminator\n",
    "\n",
    "    def _training_step_generator(self, batch, opt=None):\n",
    "        klines, multiple_close, y = batch\n",
    "        fake_close = self(klines)\n",
    "        fake = self.discriminator(torch.cat([multiple_close, fake_close], dim=1))\n",
    "        fake_generator, close_generator, sign_generator = self.generator_loss(\n",
    "            fake, fake_close, y\n",
    "        )\n",
    "        g_loss = -fake_generator + 0.5 * close_generator + 0.5 * sign_generator\n",
    "        if opt is not None:\n",
    "            opt.zero_grad()\n",
    "            self.manual_backward(g_loss)\n",
    "            opt.step()\n",
    "\n",
    "        return {\n",
    "            \"g_loss\": g_loss,\n",
    "            \"fake_generator\": fake_generator,\n",
    "            \"close_generator\": close_generator,\n",
    "            \"sign_generator\": sign_generator,\n",
    "        }\n",
    "\n",
    "    def _training_step_discriminator(self, batch, opt=None, steps=5):\n",
    "        klines, multiple_close, y = batch\n",
    "        D_loss = 0\n",
    "        Fake_discriminator = 0\n",
    "        Real_discriminator = 0\n",
    "        for _ in range(steps):\n",
    "            fake_close = self(klines)\n",
    "            fake = self.discriminator(torch.cat([multiple_close, fake_close], dim=1))\n",
    "            real = self.discriminator(torch.cat([multiple_close, y], dim=1))\n",
    "            fake_discriminator, real_discriminator = self.discriminator_loss(\n",
    "                real, fake, fake_close, y\n",
    "            )\n",
    "            d_loss = fake_discriminator - real_discriminator\n",
    "            if opt is not None:\n",
    "                opt.zero_grad()\n",
    "                self.manual_backward(d_loss)\n",
    "                opt.step()\n",
    "\n",
    "            D_loss += d_loss / steps\n",
    "            Fake_discriminator += fake_discriminator / steps\n",
    "            Real_discriminator += real_discriminator / steps\n",
    "\n",
    "        return {\n",
    "            \"d_loss\": D_loss,\n",
    "            \"fake_discriminator\": Fake_discriminator,\n",
    "            \"real_discriminator\": Real_discriminator,\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        opt_g, opt_d = self.optimizers()\n",
    "\n",
    "        metrics = {}\n",
    "        metrics.update(self._training_step_generator(batch, opt_g))\n",
    "        metrics.update(self._training_step_discriminator(batch, opt_d, steps=1))\n",
    "\n",
    "        self.log_dict(\n",
    "            metrics,\n",
    "            prog_bar=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "        )\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        metrics = {}\n",
    "        metrics.update(self._training_step_generator(batch))\n",
    "        metrics.update(self._training_step_discriminator(batch, steps=1))\n",
    "        metrics = {\n",
    "            \"val_\" + metric_name: metric_value\n",
    "            for metric_name, metric_value in metrics.items()\n",
    "        }\n",
    "\n",
    "        self.log_dict(\n",
    "            metrics,\n",
    "            prog_bar=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "        )\n",
    "        return metrics\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt_g = torch.optim.Adam(\n",
    "            self.generator.parameters(),\n",
    "            lr=self.config[\"learning_rate_generator\"],\n",
    "            # betas=(self.config[\"beta1\"], self.config[\"beta2\"]),\n",
    "        )\n",
    "        opt_d = torch.optim.Adam(\n",
    "            self.discriminator.parameters(),\n",
    "            lr=self.config[\"learning_rate_discriminator\"],\n",
    "            betas=(self.config[\"beta1\"], self.config[\"beta2\"]),\n",
    "        )\n",
    "        return opt_g, opt_d\n",
    "\n",
    "\n",
    "model = GAN(config)\n",
    "\n",
    "model_checkpoint = pl.callbacks.model_checkpoint.ModelCheckpoint(\n",
    "    dirpath=run.dir if \"run\" in locals() else \"tmp/\",\n",
    "    filename=\"{epoch}-{val_loss:.3f}\",\n",
    "    monitor=\"_generatorg_loss\",\n",
    "    mode=\"min\",\n",
    "    verbose=True,\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "script_checkpoint = training.ScriptCheckpoint(\n",
    "    dirpath=run.dir if \"run\" in locals() else \"tmp/\",\n",
    ")\n",
    "\n",
    "callbacks = [script_checkpoint]\n",
    "log = None\n",
    "if config[\"job_type\"] == \"train\" or False:\n",
    "    callbacks.append(model_checkpoint)\n",
    "    print(f\"[INFO]: saving models.\")\n",
    "else:\n",
    "    print(f\"[INFO]: not saving models.\")\n",
    "if config[\"job_type\"] == \"debug\":\n",
    "    log = \"all\"\n",
    "\n",
    "if config[\"log_wandb\"]:\n",
    "    wandb_logger = pl.loggers.WandbLogger()\n",
    "    wandb_logger.watch(model, log=log, log_graph=True)\n",
    "else:\n",
    "    wandb_logger = None\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=150,\n",
    "    callbacks=callbacks,\n",
    "    logger=wandb_logger,\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    #     limit_train_batches=3,\n",
    "    #     limit_val_batches=3,\n",
    ")\n",
    "trainer.fit(model, dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "compteur = 0\n",
    "for i in range(len(previous_x)):\n",
    "    for j in range(len(previous_x[i])):\n",
    "        if not torch.equal(previous_x[i][0], previous_x[i][j]):\n",
    "            compteur += 1\n",
    "print(compteur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "compteur = 0\n",
    "for i in range(len(preprevious_x)):\n",
    "    for j in range(len(preprevious_x[i])):\n",
    "        if not torch.equal(preprevious_x[i][0], preprevious_x[i][j]):\n",
    "            compteur += 1\n",
    "print(compteur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "compteur = 0\n",
    "for i in range(len(following_x)):\n",
    "    for j in range(len(following_x[i])):\n",
    "        if not torch.equal(following_x[i][0], following_x[i][j]):\n",
    "            compteur += 1\n",
    "print(compteur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14884/1864882645.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mklines1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mklines2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklines1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m print(\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "batch = previous_x[-1]\n",
    "klines1 = batch[14]\n",
    "klines2 = batch[15]\n",
    "print(klines1.shape)\n",
    "print(\n",
    "    model.generator.fc_layers(\n",
    "        klines1.unsqueeze(0),\n",
    "    )\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "321abdbcb709f963ff456ab1955c8b6ac962fdf45411881beed91e0e00a7d370"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit ('binance')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
